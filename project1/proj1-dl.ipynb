{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:33:41.251274Z",
          "iopub.status.busy": "2021-04-06T13:33:41.250532Z",
          "iopub.status.idle": "2021-04-06T13:33:45.940830Z",
          "shell.execute_reply": "2021-04-06T13:33:45.941746Z"
        },
        "papermill": {
          "duration": 4.73554,
          "end_time": "2021-04-06T13:33:45.942064",
          "exception": false,
          "start_time": "2021-04-06T13:33:41.206524",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te6WoFI6SX5M",
        "outputId": "71c276a6-1b09-453e-ae86-a6cf404e3486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import pandas as pd\n",
        "import random, time\n",
        "from babel.dates import format_date, format_datetime, format_time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "!pip install transformers\n",
        "import transformers, os\n",
        "from transformers import BertModel, AutoModel, AdamW, get_linear_schedule_with_warmup, BertTokenizer, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:33:46.340289Z",
          "iopub.status.busy": "2021-04-06T13:33:46.335987Z",
          "iopub.status.idle": "2021-04-06T13:33:46.355473Z",
          "shell.execute_reply": "2021-04-06T13:33:46.356308Z"
        },
        "papermill": {
          "duration": 0.354394,
          "end_time": "2021-04-06T13:33:46.356598",
          "exception": false,
          "start_time": "2021-04-06T13:33:46.002204",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lrkjdL8SX5M",
        "outputId": "7e546113-85b5-43d8-d53a-6b501cdeea81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are %d GPU(s) available. 1\n",
            "We will use the GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "# Check device\n",
        "# Get the GPU device name if available.\n",
        "if torch.cuda.is_available():\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available. {}'.format(torch.cuda.device_count()))\n",
        "    print('We will use the GPU: {}'.format(torch.cuda.get_device_name(0)))\n",
        "\n",
        "# If we dont have GPU but a CPU, training will take place on CPU instead\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:33:46.439098Z",
          "iopub.status.busy": "2021-04-06T13:33:46.438327Z",
          "iopub.status.idle": "2021-04-06T13:33:48.584484Z",
          "shell.execute_reply": "2021-04-06T13:33:48.583823Z"
        },
        "papermill": {
          "duration": 2.193877,
          "end_time": "2021-04-06T13:33:48.584656",
          "exception": false,
          "start_time": "2021-04-06T13:33:46.390779",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_3cqGhMSX5N",
        "outputId": "7b5c787b-957c-4763-ad46-9542fdd5537e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   TweetID  TimeOfDay                                              Tweet\n",
            "0     1001         17  The Bulldogs have been selected to finish 4th ...\n",
            "1     1002         22  Played disc golf. Got a tattoo. Heading to Det...\n",
            "2     1003         16  Sunday big football game I'm gunna gather all ...\n",
            "3     1004         20  Despite my resolution to be nicer to Scooter t...\n",
            "4     1005         18  Reassigned by Michigan Runner to shoot Goodlif...\n"
          ]
        }
      ],
      "source": [
        "train_file = \"train.txt\"\n",
        "label_file = \"WN23_PA_training_labels.txt\"\n",
        "test_file = \"test.txt\"\n",
        "train_df = pd.read_csv(train_file, sep = \",\",encoding = \"ISO-8859-1\")\n",
        "label_df = pd.read_csv(label_file, sep = \",\", encoding = \"ISO-8859-1\")\n",
        "test_df = pd.read_csv(test_file, sep = \",\", encoding = \"ISO-8859-1\")\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.101392,
          "end_time": "2021-04-06T13:36:16.511844",
          "exception": false,
          "start_time": "2021-04-06T13:36:16.410452",
          "status": "completed"
        },
        "tags": [],
        "id": "g8eJJ8ItSX5Q"
      },
      "source": [
        "## Term frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:36:16.718904Z",
          "iopub.status.busy": "2021-04-06T13:36:16.717717Z",
          "iopub.status.idle": "2021-04-06T13:36:16.720715Z",
          "shell.execute_reply": "2021-04-06T13:36:16.719808Z"
        },
        "papermill": {
          "duration": 0.110346,
          "end_time": "2021-04-06T13:36:16.720919",
          "exception": false,
          "start_time": "2021-04-06T13:36:16.610573",
          "status": "completed"
        },
        "tags": [],
        "id": "fTHFtk4ySX5Q"
      },
      "outputs": [],
      "source": [
        "## Check the word frequency in texts\n",
        "#\n",
        "## lemmatize text column by using a lemmatize function\n",
        "#def lemmatize_text(text):\n",
        "#    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text.lower())]\n",
        "#\n",
        "#\n",
        "## Initialize the Lemmatizer and Whitespace Tokenizer\n",
        "#w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "#lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "#\n",
        "## Lemmatize words\n",
        "#df['text_lemmatized'] = df.text.apply(lemmatize_text)\n",
        "#df['text_lemmatized'] = df['text_lemmatized'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "#\n",
        "## use explode to expand the lists into separate rows\n",
        "#wf_text = df.text_lemmatized.explode().to_frame().reset_index(drop=True)\n",
        "#\n",
        "## plot\n",
        "#sns.countplot(x='text_lemmatized', data=wf_text, order=wf_text.text_lemmatized.value_counts().iloc[:10].index)\n",
        "#plt.xlabel('Most common used words in all texts')\n",
        "#plt.ylabel('Frequency [%]')\n",
        "#plt.xticks(rotation=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:36:16.929815Z",
          "iopub.status.busy": "2021-04-06T13:36:16.928797Z",
          "iopub.status.idle": "2021-04-06T13:36:16.931747Z",
          "shell.execute_reply": "2021-04-06T13:36:16.930699Z"
        },
        "papermill": {
          "duration": 0.109884,
          "end_time": "2021-04-06T13:36:16.931974",
          "exception": false,
          "start_time": "2021-04-06T13:36:16.822090",
          "status": "completed"
        },
        "tags": [],
        "id": "-lJshs1PSX5Q"
      },
      "outputs": [],
      "source": [
        "## Check the word frequency in titles\n",
        "#\n",
        "## Lemmatize words\n",
        "#df['title_lemmatized'] = df.title.apply(lemmatize_text)\n",
        "#df['title_lemmatized'] = df['title_lemmatized'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "#\n",
        "## use explode to expand the lists into separate rows\n",
        "#wf_title = df.title_lemmatized.explode().to_frame().reset_index(drop=True)\n",
        "#\n",
        "## plot dfe\n",
        "#sns.countplot(x='title_lemmatized', data=wf_title, order=wf_title.title_lemmatized.value_counts().iloc[:10].index)\n",
        "#plt.xlabel('Most common used words in all titles')\n",
        "#plt.ylabel('Frequency [%]')\n",
        "#plt.xticks(rotation=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.078352,
          "end_time": "2021-04-06T13:36:17.113220",
          "exception": false,
          "start_time": "2021-04-06T13:36:17.034868",
          "status": "completed"
        },
        "tags": [],
        "id": "QJ56xp4vSX5Q"
      },
      "source": [
        "# Cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def regex_preprocessing(text: str) -> str:\n",
        "     url = r\"(?:http|https):\\/\\/[a-zA-Z0-9]*\\.[a-zA-Z0-9]*\\/[a-zA-Z0-9]*\\/[a-zA-Z0-9]*|(?:http|https):\\/\\/t\\.co\\/[a-zA-Z0-9]*|(?:http|https):\\/\\/[a-zA-Z0-9]*\\.[a-zA-Z0-9]*\\/[a-zA-Z0-9]*\"\n",
        "     linebreak = r\"\\n\"\n",
        "     username = r\"@[a-zA-Z0-9_]*(?! )\"\n",
        "     otherchar = r\"(?:&amp;|#|_{2,}|\\.{2,}|\\\\n|\\\\)\"\n",
        "     charnorm = r\"([A-Za-z])\\1{2,}\"\n",
        "     w = r\"w\\/\" # about\n",
        "     at = r\"@ \" # about 204 occurences\n",
        "\n",
        "     text = re.sub(url, '', text)\n",
        "     text = re.sub(linebreak, '', text)\n",
        "     text = re.sub(username, '', text)\n",
        "     text = re.sub(otherchar, '', text)\n",
        "     text = re.sub(w, \"with \", text)\n",
        "     text = re.sub(at, \"at \", text)\n",
        "     text = re.sub(charnorm, r\"\\1\", text)\n",
        "\n",
        "     return text"
      ],
      "metadata": {
        "id": "WhE1crDeICV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Tweet'] = train_df['Tweet'].apply(lambda x: regex_preprocessing(x)).apply(lambda x: \" \".join(x))\n",
        "test_df['Tweet'] = test_df['Tweet'].apply(lambda x: regex_preprocessing(x)).apply(lambda x: \" \".join(x))\n",
        "\n",
        "train_df = train_df['Tweet']\n",
        "label_df = label_df['Label']\n",
        "test_df = test_df['Tweet']"
      ],
      "metadata": {
        "id": "L2WgK4FPIGl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:36:17.243942Z",
          "iopub.status.busy": "2021-04-06T13:36:17.242925Z",
          "iopub.status.idle": "2021-04-06T13:37:33.357127Z",
          "shell.execute_reply": "2021-04-06T13:37:33.355662Z"
        },
        "papermill": {
          "duration": 76.18652,
          "end_time": "2021-04-06T13:37:33.357284",
          "exception": false,
          "start_time": "2021-04-06T13:36:17.170764",
          "status": "completed"
        },
        "tags": [],
        "id": "c-yoBM4KSX5R"
      },
      "outputs": [],
      "source": [
        "# #  Preprocess train dataset\n",
        "# # remove special characters from text column\n",
        "# text_df.Tweet = text_df.Tweet.str.replace('[#,@,&]', '')\n",
        "# # Remove digits\n",
        "# text_df.Tweet = text_df.Tweet.str.replace('\\d*','')\n",
        "# #Remove www\n",
        "# text_df.Tweet = text_df.Tweet.str.replace('w{3}','')\n",
        "# # remove urls\n",
        "# text_df.Tweet = text_df.Tweet.str.replace(\"http\\S+\", \"\")\n",
        "# # remove multiple spaces with single space\n",
        "# text_df.Tweet = text_df.Tweet.str.replace('\\s+', ' ')\n",
        "# #remove all single characters\n",
        "# text_df.Tweet = text_df.Tweet.str.replace(r'\\s+[a-zA-Z]\\s+', '')\n",
        "\n",
        "# # Remove english stopwords\n",
        "# text_df['text'] = text_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:37:33.484675Z",
          "iopub.status.busy": "2021-04-06T13:37:33.483813Z",
          "iopub.status.idle": "2021-04-06T13:37:33.493435Z",
          "shell.execute_reply": "2021-04-06T13:37:33.492826Z"
        },
        "papermill": {
          "duration": 0.075687,
          "end_time": "2021-04-06T13:37:33.493579",
          "exception": false,
          "start_time": "2021-04-06T13:37:33.417892",
          "status": "completed"
        },
        "tags": [],
        "id": "O8pSdlUfSX5R"
      },
      "outputs": [],
      "source": [
        "# Split test and train data using 25% of the dataset for validation purposes\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_df, label_df, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_Transformer, X_val_Transformer, y_train_Transformer, y_val_Transformer = train_test_split(\n",
        "                                                    x_train, y_train, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "fUYT53KEJmmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.060976,
          "end_time": "2021-04-06T13:37:33.613368",
          "exception": false,
          "start_time": "2021-04-06T13:37:33.552392",
          "status": "completed"
        },
        "tags": [],
        "id": "r1dmLlPnSX5R"
      },
      "source": [
        "# Try transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:37:33.741316Z",
          "iopub.status.busy": "2021-04-06T13:37:33.738070Z",
          "iopub.status.idle": "2021-04-06T13:37:33.745573Z",
          "shell.execute_reply": "2021-04-06T13:37:33.744906Z"
        },
        "papermill": {
          "duration": 0.073155,
          "end_time": "2021-04-06T13:37:33.745696",
          "exception": false,
          "start_time": "2021-04-06T13:37:33.672541",
          "status": "completed"
        },
        "tags": [],
        "id": "c2surFOYSX5R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:37:33.871766Z",
          "iopub.status.busy": "2021-04-06T13:37:33.870717Z",
          "iopub.status.idle": "2021-04-06T13:37:33.873953Z",
          "shell.execute_reply": "2021-04-06T13:37:33.874587Z"
        },
        "papermill": {
          "duration": 0.068768,
          "end_time": "2021-04-06T13:37:33.874750",
          "exception": false,
          "start_time": "2021-04-06T13:37:33.805982",
          "status": "completed"
        },
        "tags": [],
        "id": "GKj9oJjWSX5R"
      },
      "outputs": [],
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "SEQ_LEN = 300\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "learning_rate = 1e-5 # Controls how large a step is taken when updating model weights during training.\n",
        "steps_per_epoch = 50\n",
        "num_workers = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:37:34.016031Z",
          "iopub.status.busy": "2021-04-06T13:37:34.010954Z",
          "iopub.status.idle": "2021-04-06T13:37:37.737736Z",
          "shell.execute_reply": "2021-04-06T13:37:37.736555Z"
        },
        "papermill": {
          "duration": 3.801121,
          "end_time": "2021-04-06T13:37:37.737901",
          "exception": false,
          "start_time": "2021-04-06T13:37:33.936780",
          "status": "completed"
        },
        "tags": [],
        "id": "N-pKxYKzSX5R"
      },
      "outputs": [],
      "source": [
        "def get_split(text1):\n",
        "    '''Get split of the text with 200 char lenght'''\n",
        "    l_total = []\n",
        "    l_parcial = []\n",
        "    if len(text1.split())//150 >0:\n",
        "        n = len(text1.split())//150\n",
        "    else:\n",
        "        n = 1\n",
        "    for w in range(n):\n",
        "        if w == 0:\n",
        "            l_parcial = text1.split()[:200]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "        else:\n",
        "            l_parcial = text1.split()[w*150:w*150 + 200]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "    return str(l_total)\n",
        "\n",
        "# Splits train and validation sets to be feed to the transformer which only accepts 512 tokens maximum\n",
        "split_train_text = [get_split(t) for t in X_train_Transformer]\n",
        "split_valid_text = [get_split(t) for t in X_val_Transformer]\n",
        "split_test_text = [get_split(t) for t in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:37:37.865388Z",
          "iopub.status.busy": "2021-04-06T13:37:37.862924Z",
          "iopub.status.idle": "2021-04-06T13:37:37.866120Z",
          "shell.execute_reply": "2021-04-06T13:37:37.866618Z"
        },
        "papermill": {
          "duration": 0.069856,
          "end_time": "2021-04-06T13:37:37.866775",
          "exception": false,
          "start_time": "2021-04-06T13:37:37.796919",
          "status": "completed"
        },
        "tags": [],
        "id": "SxY6TAWNSX5R"
      },
      "outputs": [],
      "source": [
        "#split_valid_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:37:37.990831Z",
          "iopub.status.busy": "2021-04-06T13:37:37.990098Z",
          "iopub.status.idle": "2021-04-06T13:37:39.097551Z",
          "shell.execute_reply": "2021-04-06T13:37:39.097043Z"
        },
        "papermill": {
          "duration": 1.174267,
          "end_time": "2021-04-06T13:37:39.097703",
          "exception": false,
          "start_time": "2021-04-06T13:37:37.923436",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "12b572b8ad6b4b108b1ba62b178bd849",
            "a57bcf265f08413cac0253c6fdbc1572",
            "5529ff7d8e814e48822a88ef24ff81bc",
            "75c21f3ae2a34a189ab835a3448e32bd",
            "b7727b01edd845acbcff660a846ca5de",
            "604e7ff2cd7b450d85ed2073233066a5",
            "7f5d918afe294340868ab0d4314c15aa",
            "cf111c7784db4d929e1812b31db44da9",
            "60654f522988419fad7f599441e81fac",
            "be90b602e3e74518b4eeeb0718ab6581",
            "259783494f934557b28f05c5604f4a2a",
            "34c561f3606c4d59b5121427f6a054fe",
            "2ba17b4a81274f2e825b29584396cc6c",
            "1928a62cd09d43b09907676359490d45",
            "de13aae110cc44a29727ec04663e6284",
            "839020bfa94e4464b23c309bc2e3ef2b",
            "20261a9ee7f34af492b4ed368406b91e",
            "679870e0aa1c45a8af873bbed00f22ad",
            "1e2d32d3606546d08869939f214442ac",
            "8a7d7f814f8844cbb8c84f87887b6f21",
            "c91f0a88f9e2410aa13d1e351c7f55a1",
            "2a15d4a36e7e4bc49b147e0c5b7ee2e4",
            "e7155b8b9bc54fc795a18a4b7ffe7214",
            "ce97b64f0e26471aa9c4e1c2ae570073",
            "f9acbe188f5c44029159eafb25b53c5d",
            "af05800354c84b39b245393e9ce59d16",
            "963fff97ba4d4329b6fc9bb9e1a08171",
            "19a2a3a5ce4d4a3b808216518fceecd8",
            "24d9049644864e6fb01f6bdcc5b50a75",
            "4219d943bd5b460197964c1753aa31f7",
            "87f4a594d0634a69bed099af82771d69",
            "c5bf61ced64a4718b8b4c2c14212ed99",
            "889ec3936fce45418f7b2af6114c63a6"
          ]
        },
        "id": "PsDSByGxSX5R",
        "outputId": "dd1060ab-441f-4178-df4b-67bb9a3ab5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12b572b8ad6b4b108b1ba62b178bd849"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34c561f3606c4d59b5121427f6a054fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7155b8b9bc54fc795a18a4b7ffe7214"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the RoBERTa tokenizer and tokenize the data\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:37:39.245670Z",
          "iopub.status.busy": "2021-04-06T13:37:39.240747Z",
          "iopub.status.idle": "2021-04-06T13:45:43.373214Z",
          "shell.execute_reply": "2021-04-06T13:45:43.372617Z"
        },
        "papermill": {
          "duration": 484.213594,
          "end_time": "2021-04-06T13:45:43.373403",
          "exception": false,
          "start_time": "2021-04-06T13:37:39.159809",
          "status": "completed"
        },
        "tags": [],
        "id": "GKi--yFmSX5R"
      },
      "outputs": [],
      "source": [
        "trencoding = tokenizer.batch_encode_plus(\n",
        "  list(split_train_text),\n",
        "  max_length=SEQ_LEN,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=True,\n",
        "  truncation=True,\n",
        "  padding='longest',\n",
        "  return_attention_mask=True,\n",
        ")\n",
        "\n",
        "valencoding = tokenizer.batch_encode_plus(\n",
        "  list(split_valid_text),\n",
        "  max_length=SEQ_LEN,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=True,\n",
        "  truncation=True,\n",
        "  padding='longest',\n",
        "  return_attention_mask=True,\n",
        ")\n",
        "\n",
        "\n",
        "testencoding = tokenizer.batch_encode_plus(\n",
        "  list(split_test_text),\n",
        "  max_length=SEQ_LEN,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=True,\n",
        "  truncation=True,\n",
        "  padding='longest',\n",
        "  return_attention_mask=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:45:43.503117Z",
          "iopub.status.busy": "2021-04-06T13:45:43.502045Z",
          "iopub.status.idle": "2021-04-06T13:45:43.508024Z",
          "shell.execute_reply": "2021-04-06T13:45:43.507527Z"
        },
        "papermill": {
          "duration": 0.072342,
          "end_time": "2021-04-06T13:45:43.508161",
          "exception": false,
          "start_time": "2021-04-06T13:45:43.435819",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbBkyJVFSX5R",
        "outputId": "6002bddd-f03d-481a-9ac3-508915f5e711"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'unk_token': '[UNK]',\n",
              " 'sep_token': '[SEP]',\n",
              " 'pad_token': '[PAD]',\n",
              " 'cls_token': '[CLS]',\n",
              " 'mask_token': '[MASK]'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "tokenizer.special_tokens_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:45:43.635810Z",
          "iopub.status.busy": "2021-04-06T13:45:43.634230Z",
          "iopub.status.idle": "2021-04-06T13:45:43.638331Z",
          "shell.execute_reply": "2021-04-06T13:45:43.638915Z"
        },
        "papermill": {
          "duration": 0.071148,
          "end_time": "2021-04-06T13:45:43.639102",
          "exception": false,
          "start_time": "2021-04-06T13:45:43.567954",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y97XwOJQSX5R",
        "outputId": "2386b25f-8ee6-46b1-f9e8-05134efbc136"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "trencoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.059674,
          "end_time": "2021-04-06T13:45:43.756611",
          "exception": false,
          "start_time": "2021-04-06T13:45:43.696937",
          "status": "completed"
        },
        "tags": [],
        "id": "emkBcW3uSX5R"
      },
      "source": [
        "## Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OA5ytU4MDBN",
        "outputId": "fe84b685-2a5b-403f-f9f8-de41ec5c0187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:45:43.901497Z",
          "iopub.status.busy": "2021-04-06T13:45:43.900363Z",
          "iopub.status.idle": "2021-04-06T13:45:48.436708Z",
          "shell.execute_reply": "2021-04-06T13:45:48.435454Z"
        },
        "papermill": {
          "duration": 4.618857,
          "end_time": "2021-04-06T13:45:48.436866",
          "exception": false,
          "start_time": "2021-04-06T13:45:43.818009",
          "status": "completed"
        },
        "tags": [],
        "id": "nsrZU193SX5S"
      },
      "outputs": [],
      "source": [
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight = 'balanced',\n",
        "                                 classes=np.unique(np.unique(y_train)),\n",
        "                                 y=y_train\n",
        "                                 )\n",
        "\n",
        "#print(class_wts)\n",
        "\n",
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "#cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "cross_entropy  = nn.CrossEntropyLoss(weight=weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:45:50.525090Z",
          "iopub.status.busy": "2021-04-06T13:45:50.241774Z",
          "iopub.status.idle": "2021-04-06T13:45:51.473787Z",
          "shell.execute_reply": "2021-04-06T13:45:51.474838Z"
        },
        "papermill": {
          "duration": 2.969003,
          "end_time": "2021-04-06T13:45:51.475027",
          "exception": false,
          "start_time": "2021-04-06T13:45:48.506024",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hef8gYt8SX5S",
        "outputId": "a71f3c72-88ae-468a-a141-31550f947133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data in the train set 160\n",
            "Number of data in the validation set 40\n",
            "Number of data in the test set 50\n"
          ]
        }
      ],
      "source": [
        "def loadData(prep_df, batch_size, num_workers, sampler):\n",
        "\n",
        "    return  DataLoader(\n",
        "            prep_df,\n",
        "            batch_size=batch_size,\n",
        "            num_workers=num_workers,\n",
        "            sampler=sampler,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "## convert lists to tensors\n",
        "train_seq = torch.tensor(trencoding['input_ids'])\n",
        "train_mask = torch.tensor(trencoding['attention_mask'])\n",
        "train_token_ids = torch.tensor(trencoding['token_type_ids'])\n",
        "train_y = torch.tensor(y_train_Transformer.tolist())\n",
        "\n",
        "val_seq = torch.tensor(valencoding['input_ids'])\n",
        "val_mask = torch.tensor(valencoding['attention_mask'])\n",
        "val_token_ids = torch.tensor(valencoding['token_type_ids'])\n",
        "val_y = torch.tensor(y_val_Transformer.tolist())\n",
        "\n",
        "test_seq = torch.tensor(testencoding['input_ids'])\n",
        "test_mask = torch.tensor(testencoding['attention_mask'])\n",
        "test_token_ids = torch.tensor(testencoding['token_type_ids'])\n",
        "test_y = torch.tensor(y_test.tolist())\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_token_ids, train_y)\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# Train Data Loader\n",
        "traindata = loadData(train_data, batch_size, num_workers, train_sampler)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_token_ids, val_y)\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "# Val Data Loader\n",
        "valdata = loadData(val_data, batch_size, num_workers, val_sampler)\n",
        "\n",
        "# wrap tensors\n",
        "test_data = TensorDataset(test_seq, test_mask, test_token_ids, test_y)\n",
        "# sampler for sampling the data during training\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "# Val Data Loader\n",
        "testdata = loadData(test_data, batch_size, num_workers, test_sampler)\n",
        "\n",
        "\n",
        "print('Number of data in the train set', len(traindata))\n",
        "print('Number of data in the validation set', len(valdata))\n",
        "print('Number of data in the test set', len(testdata))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:45:51.705878Z",
          "iopub.status.busy": "2021-04-06T13:45:51.703031Z",
          "iopub.status.idle": "2021-04-06T13:45:51.708502Z",
          "shell.execute_reply": "2021-04-06T13:45:51.707827Z"
        },
        "papermill": {
          "duration": 0.125755,
          "end_time": "2021-04-06T13:45:51.708645",
          "exception": false,
          "start_time": "2021-04-06T13:45:51.582890",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d1i_4o2SX5S",
        "outputId": "fba0ac7c-e045-4a5b-93f4-b2bd1d66b3e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.059363,
          "end_time": "2021-04-06T13:45:51.834144",
          "exception": false,
          "start_time": "2021-04-06T13:45:51.774781",
          "status": "completed"
        },
        "tags": [],
        "id": "CG9TIJwDSX5S"
      },
      "source": [
        "# Load BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:45:51.968056Z",
          "iopub.status.busy": "2021-04-06T13:45:51.965708Z",
          "iopub.status.idle": "2021-04-06T13:45:51.968769Z",
          "shell.execute_reply": "2021-04-06T13:45:51.969245Z"
        },
        "papermill": {
          "duration": 0.074488,
          "end_time": "2021-04-06T13:45:51.969420",
          "exception": false,
          "start_time": "2021-04-06T13:45:51.894932",
          "status": "completed"
        },
        "tags": [],
        "id": "5rJ9QnXwSX5S"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes, freeze_bert=False):\n",
        "\n",
        "        super(BERT_Arch,self).__init__()\n",
        "        # Instantiating BERT model object\n",
        "        self.bert = BertModel.from_pretrained(model_name, return_dict=False)\n",
        "\n",
        "        # Freeze bert layers\n",
        "        if freeze_bert:\n",
        "            for p in self.bert.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.bert_drop_1 = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size) # (768, 64)\n",
        "        self.bn = nn.BatchNorm1d(768) # (768)\n",
        "        self.bert_drop_2 = nn.Dropout(0.25)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes) # (768,2)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        _, output = self.bert(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            token_type_ids = token_type_ids\n",
        "        )\n",
        "        output = self.bert_drop_1(output)\n",
        "        output = self.fc(output)\n",
        "        output = self.bn(output)\n",
        "        output = self.bert_drop_2(output)\n",
        "        output = self.out(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:45:52.097160Z",
          "iopub.status.busy": "2021-04-06T13:45:52.095323Z",
          "iopub.status.idle": "2021-04-06T13:46:19.038731Z",
          "shell.execute_reply": "2021-04-06T13:46:19.039313Z"
        },
        "papermill": {
          "duration": 27.011308,
          "end_time": "2021-04-06T13:46:19.039580",
          "exception": false,
          "start_time": "2021-04-06T13:45:52.028272",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "6afe18b3778346068989ac8d21a60dcc",
            "00a24a670838490da13f5786774bfe17",
            "1948be8f3288454e9ecab1e3697c3512",
            "3773e811e41e4bf8bc421cf676037e99",
            "0da0bc303dde4d54b4b477dffe2da1c1",
            "8c3490bc3a904ccc98094d6fca478188",
            "6727cd7665c949a9b2c81d7da457ea9f",
            "cce0fde6917b4e8e8ddb75959f8f1bf3",
            "41dcc04cba5f47798f959983825ad2e9",
            "113149a4154549f492c22ae51d459a73",
            "d20b91d8ada74f6aac01d8cb3b57f916"
          ]
        },
        "id": "WnIOK8QgSX5S",
        "outputId": "15251676-ad8f-4352-8727-55e0b697de69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the BERT custom model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6afe18b3778346068989ac8d21a60dcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing the optimizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class_names = np.unique(label_df)\n",
        "print('Downloading the BERT custom model...')\n",
        "model = BERT_Arch(len(class_names))\n",
        "model.to(device) # Model to GPU.\n",
        "\n",
        "#optimizer parameters\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "optimizer_parameters = [{'params': [p for n, p in param_optimizer\n",
        "                                    if not any(nd in n for nd in no_decay)],'weight_decay':0.001},\n",
        "                        {'params': [p for n, p in param_optimizer\n",
        "                                    if any(nd in n for nd in no_decay)],'weight_decay':0.0}]\n",
        "\n",
        "print('Preparing the optimizer...')\n",
        "#optimizer\n",
        "optimizer = AdamW(optimizer_parameters, lr=learning_rate)\n",
        "steps = steps_per_epoch\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.069214,
          "end_time": "2021-04-06T13:46:19.177396",
          "exception": false,
          "start_time": "2021-04-06T13:46:19.108182",
          "status": "completed"
        },
        "tags": [],
        "id": "IJ-TAR6PSX5S"
      },
      "source": [
        "## Train the BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:46:19.327531Z",
          "iopub.status.busy": "2021-04-06T13:46:19.326365Z",
          "iopub.status.idle": "2021-04-06T13:46:19.330031Z",
          "shell.execute_reply": "2021-04-06T13:46:19.329519Z"
        },
        "papermill": {
          "duration": 0.08423,
          "end_time": "2021-04-06T13:46:19.330203",
          "exception": false,
          "start_time": "2021-04-06T13:46:19.245973",
          "status": "completed"
        },
        "tags": [],
        "id": "uf3rZHDySX5S"
      },
      "outputs": [],
      "source": [
        "# function to train the bert model\n",
        "def trainBERT():\n",
        "\n",
        "    print('Training...')\n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "\n",
        "    # iterate over batches\n",
        "    for step, batch in enumerate(traindata):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(traindata)))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            # push the batch to gpu\n",
        "            batch = [r.to(device) for r in batch]\n",
        "\n",
        "        sent_id, mask, token_type_ids, labels = batch\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask, token_type_ids)\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "        # append the model predictions\n",
        "        total_preds.append(preds)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(traindata)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:46:19.477677Z",
          "iopub.status.busy": "2021-04-06T13:46:19.476805Z",
          "iopub.status.idle": "2021-04-06T13:46:19.480692Z",
          "shell.execute_reply": "2021-04-06T13:46:19.480156Z"
        },
        "papermill": {
          "duration": 0.082125,
          "end_time": "2021-04-06T13:46:19.480839",
          "exception": false,
          "start_time": "2021-04-06T13:46:19.398714",
          "status": "completed"
        },
        "tags": [],
        "id": "h0XWWwLhSX5S"
      },
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval() # deactivate dropout layers\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step, batch in enumerate(valdata):\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(valdata)))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            # push the batch to gpu\n",
        "            batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, token_type_ids, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad(): # Dont store any previous computations, thus freeing GPU space\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask, token_type_ids)\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds, labels)\n",
        "            total_loss = total_loss + loss.item()\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            total_preds.append(preds)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(valdata)\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T13:46:19.626337Z",
          "iopub.status.busy": "2021-04-06T13:46:19.625587Z",
          "iopub.status.idle": "2021-04-06T15:00:48.652211Z",
          "shell.execute_reply": "2021-04-06T15:00:48.652798Z"
        },
        "papermill": {
          "duration": 4469.104245,
          "end_time": "2021-04-06T15:00:48.652979",
          "exception": false,
          "start_time": "2021-04-06T13:46:19.548734",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSKKbYiwSX5S",
        "outputId": "c5fe8b9e-8c51-4375-889e-67111ab72aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Training...\n",
            "  Batch    50  of    160.\n",
            "  Batch   100  of    160.\n",
            "  Batch   150  of    160.\n",
            "\n",
            "Evaluating...\n",
            "Evaluation done for epoch 1\n",
            "Saving model...\n",
            "\n",
            "Training Loss: 0.772\n",
            "Validation Loss: 0.676\n",
            "\n",
            " Epoch 2 / 5\n",
            "Training...\n",
            "  Batch    50  of    160.\n",
            "  Batch   100  of    160.\n",
            "  Batch   150  of    160.\n",
            "\n",
            "Evaluating...\n",
            "Evaluation done for epoch 2\n",
            "Saving model...\n",
            "\n",
            "Training Loss: 0.746\n",
            "Validation Loss: 0.667\n",
            "\n",
            " Epoch 3 / 5\n",
            "Training...\n",
            "  Batch    50  of    160.\n",
            "  Batch   100  of    160.\n",
            "  Batch   150  of    160.\n",
            "\n",
            "Evaluating...\n",
            "Evaluation done for epoch 3\n",
            "\n",
            "Training Loss: 0.729\n",
            "Validation Loss: 0.686\n",
            "\n",
            " Epoch 4 / 5\n",
            "Training...\n",
            "  Batch    50  of    160.\n",
            "  Batch   100  of    160.\n",
            "  Batch   150  of    160.\n",
            "\n",
            "Evaluating...\n",
            "Evaluation done for epoch 4\n",
            "Saving model...\n",
            "\n",
            "Training Loss: 0.712\n",
            "Validation Loss: 0.646\n",
            "\n",
            " Epoch 5 / 5\n",
            "Training...\n",
            "  Batch    50  of    160.\n",
            "  Batch   100  of    160.\n",
            "  Batch   150  of    160.\n",
            "\n",
            "Evaluating...\n",
            "Evaluation done for epoch 5\n",
            "Saving model...\n",
            "\n",
            "Training Loss: 0.666\n",
            "Validation Loss: 0.638\n"
          ]
        }
      ],
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# Empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "# for each epoch perform training and evaluation\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = trainBERT()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    print('Evaluation done for epoch {}'.format(epoch + 1))\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        print('Saving model...')\n",
        "        torch.save(model.state_dict(), 'bert_weights.pt') # Save model weight's (you can also save it in .bin format)\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:00:48.916578Z",
          "iopub.status.busy": "2021-04-06T15:00:48.915284Z",
          "iopub.status.idle": "2021-04-06T15:04:32.479909Z",
          "shell.execute_reply": "2021-04-06T15:04:32.479000Z"
        },
        "papermill": {
          "duration": 223.701145,
          "end_time": "2021-04-06T15:04:32.480069",
          "exception": false,
          "start_time": "2021-04-06T15:00:48.778924",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NypeTzgSX5T",
        "outputId": "df14cd54-2706-4c71-f5ef-7e5a02552df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set...\n",
            "Total batches: 50\n",
            "\n",
            "Fold Model 0\n",
            "Batch 50\n",
            "Fold Model 1\n",
            "Batch 50\n",
            "Fold Model 2\n",
            "Batch 50\n",
            "Prediction complete.\n"
          ]
        }
      ],
      "source": [
        "print('\\nTest Set...')\n",
        "\n",
        "test_preds = []\n",
        "\n",
        "print('Total batches:', len(testdata))\n",
        "\n",
        "for fold_index in range(0, 3):\n",
        "\n",
        "    print('\\nFold Model', fold_index)\n",
        "\n",
        "    # Load the fold model\n",
        "    path_model = 'bert_weights.pt'\n",
        "    model.load_state_dict(torch.load(path_model))\n",
        "\n",
        "    # Send the model to the GPU\n",
        "    model.to(device)\n",
        "\n",
        "    stacked_val_labels = []\n",
        "\n",
        "    # Put the model in evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    # Turn off the gradient calculations.\n",
        "    # This tells the model not to compute or store gradients.\n",
        "    # This step saves memory and speeds up validation.\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_val_loss = 0\n",
        "\n",
        "    for j, test_batch in enumerate(testdata):\n",
        "\n",
        "        inference_status = 'Batch ' + str(j + 1)\n",
        "\n",
        "        print(inference_status, end='\\r')\n",
        "\n",
        "        b_input_ids = test_batch[0].to(device)\n",
        "        b_input_mask = test_batch[1].to(device)\n",
        "        b_token_type_ids = test_batch[2].to(device)\n",
        "        b_test_y = test_batch[3].to(device)\n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        token_type_ids=b_token_type_ids)\n",
        "\n",
        "        # Get the preds\n",
        "        preds = outputs[0]\n",
        "\n",
        "        # Move preds to the CPU\n",
        "        val_preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        #true_labels.append(b_test_y.to('cpu').numpy().flatten())\n",
        "\n",
        "        # Stack the predictions.\n",
        "        if j == 0:  # first batch\n",
        "            stacked_val_preds = val_preds\n",
        "\n",
        "        else:\n",
        "            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "\n",
        "    test_preds.append(stacked_val_preds)\n",
        "\n",
        "\n",
        "print('\\nPrediction complete.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(test_file, sep = \",\", encoding = \"ISO-8859-1\")\n",
        "test_df['Tweet'] = test_df['Tweet'].apply(lambda x: regex_preprocessing(x)).apply(lambda x: \" \".join(x))\n",
        "test_df = test_df['Tweet']\n",
        "\n",
        "split_test_text = [get_split(t) for t in test_df]\n",
        "testencoding = tokenizer.batch_encode_plus(\n",
        "  list(split_test_text),\n",
        "  max_length=SEQ_LEN,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=True,\n",
        "  truncation=True,\n",
        "  padding='longest',\n",
        "  return_attention_mask=True,\n",
        ")\n",
        "\n",
        "test_y = torch.tensor(y_test.tolist())\n",
        "# wrap tensors\n",
        "test_data = TensorDataset(test_seq, test_mask, test_token_ids, test_y)\n",
        "# sampler for sampling the data during training\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "# Val Data Loader\n",
        "testdata = loadData(test_data, batch_size, num_workers, test_sampler)\n",
        "\n",
        "print('\\nTest Set...')\n",
        "\n",
        "test_preds = []\n",
        "\n",
        "print('Total batches:', len(testdata))\n",
        "\n",
        "for fold_index in range(0, 3):\n",
        "\n",
        "    print('\\nFold Model', fold_index)\n",
        "\n",
        "    # Load the fold model\n",
        "    path_model = 'bert_weights.pt'\n",
        "    model.load_state_dict(torch.load(path_model))\n",
        "\n",
        "    # Send the model to the GPU\n",
        "    model.to(device)\n",
        "\n",
        "    stacked_val_labels = []\n",
        "\n",
        "    # Put the model in evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    # Turn off the gradient calculations.\n",
        "    # This tells the model not to compute or store gradients.\n",
        "    # This step saves memory and speeds up validation.\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_val_loss = 0\n",
        "\n",
        "    for j, test_batch in enumerate(testdata):\n",
        "\n",
        "        inference_status = 'Batch ' + str(j + 1)\n",
        "\n",
        "        print(inference_status, end='\\r')\n",
        "\n",
        "        b_input_ids = test_batch[0].to(device)\n",
        "        b_input_mask = test_batch[1].to(device)\n",
        "        b_token_type_ids = test_batch[2].to(device)\n",
        "        b_test_y = test_batch[3].to(device)\n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        token_type_ids=b_token_type_ids)\n",
        "\n",
        "        # Get the preds\n",
        "        preds = outputs[0]\n",
        "\n",
        "        # Move preds to the CPU\n",
        "        val_preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        #true_labels.append(b_test_y.to('cpu').numpy().flatten())\n",
        "\n",
        "        # Stack the predictions.\n",
        "        if j == 0:  # first batch\n",
        "            stacked_val_preds = val_preds\n",
        "\n",
        "        else:\n",
        "            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "\n",
        "    test_preds.append(stacked_val_preds)\n",
        "\n",
        "\n",
        "print('\\nPrediction complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4BgAa8kRIzx",
        "outputId": "7e8e391d-d009-4d93-9667-d7f25f95c9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set...\n",
            "Total batches: 50\n",
            "\n",
            "Fold Model 0\n",
            "Batch 50\n",
            "Fold Model 1\n",
            "Batch 50\n",
            "Fold Model 2\n",
            "Batch 50\n",
            "Prediction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_y)"
      ],
      "metadata": {
        "id": "o1aRv7AdTWgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:04:33.539705Z",
          "iopub.status.busy": "2021-04-06T15:04:33.538702Z",
          "iopub.status.idle": "2021-04-06T15:04:33.545238Z",
          "shell.execute_reply": "2021-04-06T15:04:33.545985Z"
        },
        "papermill": {
          "duration": 0.558532,
          "end_time": "2021-04-06T15:04:33.546172",
          "exception": false,
          "start_time": "2021-04-06T15:04:32.987640",
          "status": "completed"
        },
        "tags": [],
        "id": "ZVK4CR3FSX5T"
      },
      "outputs": [],
      "source": [
        "print(len(test_preds))\n",
        "print(test_preds[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:04:34.510626Z",
          "iopub.status.busy": "2021-04-06T15:04:34.507564Z",
          "iopub.status.idle": "2021-04-06T15:04:34.517953Z",
          "shell.execute_reply": "2021-04-06T15:04:34.516836Z"
        },
        "papermill": {
          "duration": 0.492422,
          "end_time": "2021-04-06T15:04:34.518095",
          "exception": false,
          "start_time": "2021-04-06T15:04:34.025673",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSlGPk2uSX5T",
        "outputId": "20ae4c02-125f-4c3d-ee81-33f749e1ab59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "50\n",
            "\n",
            "[1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "# Sum the predictions of all fold models\n",
        "for i, item in enumerate(test_preds):\n",
        "    if i == 0:\n",
        "        preds = item\n",
        "    else:\n",
        "        # Sum the matrices\n",
        "        preds = item + preds\n",
        "\n",
        "# Average the predictions\n",
        "avg_preds = preds/(len(test_preds))\n",
        "\n",
        "#print(preds)\n",
        "#print()\n",
        "#print(avg_preds)\n",
        "\n",
        "# Take the argmax.\n",
        "# This returns the column index of the max value in each row.\n",
        "test_predictions = np.argmax(avg_preds, axis=1)\n",
        "\n",
        "# Take a look of the output\n",
        "print(type(test_predictions))\n",
        "print(len(test_predictions))\n",
        "print()\n",
        "print(test_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:04:35.480728Z",
          "iopub.status.busy": "2021-04-06T15:04:35.478485Z",
          "iopub.status.idle": "2021-04-06T15:04:38.498512Z",
          "shell.execute_reply": "2021-04-06T15:04:38.499617Z"
        },
        "papermill": {
          "duration": 3.501853,
          "end_time": "2021-04-06T15:04:38.499801",
          "exception": false,
          "start_time": "2021-04-06T15:04:34.997948",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyD4ZzqYSX5T",
        "outputId": "7cd6a375-c678-4e59-d556-286c8dbc2a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "true_y = []\n",
        "for j, test_batch in enumerate(testdata):\n",
        "    true_y.append(int(test_batch[3][0].numpy().flatten()))\n",
        "print(true_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:04:39.396577Z",
          "iopub.status.busy": "2021-04-06T15:04:39.395921Z",
          "iopub.status.idle": "2021-04-06T15:04:39.614581Z",
          "shell.execute_reply": "2021-04-06T15:04:39.613445Z"
        },
        "papermill": {
          "duration": 0.673783,
          "end_time": "2021-04-06T15:04:39.614774",
          "exception": false,
          "start_time": "2021-04-06T15:04:38.940991",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "uFqdM833SX5T",
        "outputId": "8cbdf0dc-8ccd-4c56-d1d2-70d58af2f5c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Accuracy and classification report\n",
        "target_names = ['true_y', 'predicted_y']\n",
        "\n",
        "data = {'true_y': true_y,\n",
        "       'predicted_y': test_predictions}\n",
        "\n",
        "df_pred_BERT = pd.DataFrame(data, columns=['true_y','predicted_y'])\n",
        "\n",
        "confusion_matrix = pd.crosstab(df_pred_BERT['true_y'], df_pred_BERT['predicted_y'], rownames=['True'], colnames=['Predicted'])\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:04:40.517134Z",
          "iopub.status.busy": "2021-04-06T15:04:40.516204Z",
          "iopub.status.idle": "2021-04-06T15:04:40.523557Z",
          "shell.execute_reply": "2021-04-06T15:04:40.524547Z"
        },
        "papermill": {
          "duration": 0.459775,
          "end_time": "2021-04-06T15:04:40.524778",
          "exception": false,
          "start_time": "2021-04-06T15:04:40.065003",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo6fdMfJSX5T",
        "outputId": "e90b31b1-8c91-46d1-be38-a8a6c92fa1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of BERT model 0.72\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy of BERT model', accuracy_score(true_y, test_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:04:41.745552Z",
          "iopub.status.busy": "2021-04-06T15:04:41.744546Z",
          "iopub.status.idle": "2021-04-06T15:04:41.757384Z",
          "shell.execute_reply": "2021-04-06T15:04:41.756286Z"
        },
        "papermill": {
          "duration": 0.790549,
          "end_time": "2021-04-06T15:04:41.757622",
          "exception": false,
          "start_time": "2021-04-06T15:04:40.967073",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlTtBUVOSX5T",
        "outputId": "7e43df88-990f-4726-d306-cdab5608c404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      true_y       0.90      0.61      0.73        31\n",
            " predicted_y       0.59      0.89      0.71        19\n",
            "\n",
            "    accuracy                           0.72        50\n",
            "   macro avg       0.75      0.75      0.72        50\n",
            "weighted avg       0.78      0.72      0.72        50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(true_y, test_predictions, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.442116,
          "end_time": "2021-04-06T15:04:42.678651",
          "exception": false,
          "start_time": "2021-04-06T15:04:42.236535",
          "status": "completed"
        },
        "tags": [],
        "id": "i64AwKzISX5T"
      },
      "source": [
        "# Try Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.452111,
          "end_time": "2021-04-06T15:04:43.602074",
          "exception": false,
          "start_time": "2021-04-06T15:04:43.149963",
          "status": "completed"
        },
        "tags": [],
        "id": "-Rx1ppYVSX5T"
      },
      "source": [
        "In this section I am going to train a Logistic Regression model by using a Pipeline containing the TfidfVectorizer and LogisticRegression. Also, I am going to apply a GridSearchCV to the Pipeline to find the best parameters for the model. This is going to find the optimal parameters, however, it's a bit time consuming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:04:44.810942Z",
          "iopub.status.busy": "2021-04-06T15:04:44.808050Z",
          "iopub.status.idle": "2021-04-06T15:04:44.816786Z",
          "shell.execute_reply": "2021-04-06T15:04:44.817676Z"
        },
        "papermill": {
          "duration": 0.738592,
          "end_time": "2021-04-06T15:04:44.817912",
          "exception": false,
          "start_time": "2021-04-06T15:04:44.079320",
          "status": "completed"
        },
        "tags": [],
        "id": "VCZ8izkaSX5T"
      },
      "outputs": [],
      "source": [
        "# Create a Pipeline with the TfidfVectorizer and LogisticRegression model\n",
        "LR_pipeline = Pipeline(steps = [('tf', TfidfVectorizer()),\n",
        "                                ('lgrg', LogisticRegression())]) # initialize TfidfVectorizer and LogisticRegression\n",
        "\n",
        "\n",
        "# Create Parameter Grid\n",
        "pgrid_lgrg = {\n",
        " 'tf__max_features' : [1000, 2000, 3000],\n",
        " 'tf__ngram_range' : [(1,1),(1,2)],\n",
        " 'tf__use_idf' : [True, False],\n",
        " 'lgrg__penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
        " 'lgrg__class_weight' : ['balanced', None]\n",
        "}\n",
        "\n",
        "# Apply GridSearch to Pipeline to find the best parameters\n",
        "gs_lgrg = GridSearchCV(LR_pipeline, pgrid_lgrg, cv=2, n_jobs=-1, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:04:46.025070Z",
          "iopub.status.busy": "2021-04-06T15:04:46.024106Z",
          "iopub.status.idle": "2021-04-06T15:49:20.220204Z",
          "shell.execute_reply": "2021-04-06T15:49:20.220779Z"
        },
        "papermill": {
          "duration": 2674.647373,
          "end_time": "2021-04-06T15:49:20.220947",
          "exception": false,
          "start_time": "2021-04-06T15:04:45.573574",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "NQj8zwtoSX5T",
        "outputId": "6f077051-4c74-4f85-d7d0-3b31f51f8a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "192 fits failed out of a total of 192.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "192 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 348, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\", line 2077, in fit_transform\n",
            "    X = super().fit_transform(raw_documents)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\", line 1330, in fit_transform\n",
            "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\", line 1220, in _count_vocab\n",
            "    raise ValueError(\n",
            "ValueError: empty vocabulary; perhaps the documents only contain stop words\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-78b4f4df3203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs_lgrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Train LR model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \"\"\"\n\u001b[1;32m   2076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1221\u001b[0m                     \u001b[0;34m\"empty vocabulary; perhaps the documents only contain stop words\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
          ]
        }
      ],
      "source": [
        "gs_lgrg.fit(x_train, y_train) # Train LR model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:49:21.158402Z",
          "iopub.status.busy": "2021-04-06T15:49:21.157370Z",
          "iopub.status.idle": "2021-04-06T15:49:21.162364Z",
          "shell.execute_reply": "2021-04-06T15:49:21.161847Z"
        },
        "papermill": {
          "duration": 0.47516,
          "end_time": "2021-04-06T15:49:21.162496",
          "exception": false,
          "start_time": "2021-04-06T15:49:20.687336",
          "status": "completed"
        },
        "tags": [],
        "id": "i50lkgu4SX5T"
      },
      "outputs": [],
      "source": [
        "gs_lgrg.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:49:22.091580Z",
          "iopub.status.busy": "2021-04-06T15:49:22.076426Z",
          "iopub.status.idle": "2021-04-06T15:49:46.128385Z",
          "shell.execute_reply": "2021-04-06T15:49:46.127257Z"
        },
        "papermill": {
          "duration": 24.518028,
          "end_time": "2021-04-06T15:49:46.128546",
          "exception": false,
          "start_time": "2021-04-06T15:49:21.610518",
          "status": "completed"
        },
        "tags": [],
        "id": "NTuSyLajSX5T"
      },
      "outputs": [],
      "source": [
        "print('Score of train set', gs_lgrg.score(x_train, y_train))\n",
        "print('Score of test set',gs_lgrg.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:49:47.080105Z",
          "iopub.status.busy": "2021-04-06T15:49:47.075553Z",
          "iopub.status.idle": "2021-04-06T15:49:53.014978Z",
          "shell.execute_reply": "2021-04-06T15:49:53.014484Z"
        },
        "papermill": {
          "duration": 6.429101,
          "end_time": "2021-04-06T15:49:53.015118",
          "exception": false,
          "start_time": "2021-04-06T15:49:46.586017",
          "status": "completed"
        },
        "tags": [],
        "id": "8_oh3391SX5T"
      },
      "outputs": [],
      "source": [
        "LR_pred = gs_lgrg.predict(x_test) # Predict on validation data\n",
        "\n",
        "data = {'true_y': y_test,\n",
        "       'predicted_y': LR_pred}\n",
        "df_pred = pd.DataFrame(data, columns=['true_y','predicted_y'])\n",
        "confusion_matrix = pd.crosstab(df_pred['true_y'], df_pred['predicted_y'], rownames=['True'], colnames=['Predicted'])\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:49:53.964028Z",
          "iopub.status.busy": "2021-04-06T15:49:53.962926Z",
          "iopub.status.idle": "2021-04-06T15:49:53.970035Z",
          "shell.execute_reply": "2021-04-06T15:49:53.971724Z"
        },
        "papermill": {
          "duration": 0.500368,
          "end_time": "2021-04-06T15:49:53.971926",
          "exception": false,
          "start_time": "2021-04-06T15:49:53.471558",
          "status": "completed"
        },
        "tags": [],
        "id": "k-v8SYVwSX5U"
      },
      "outputs": [],
      "source": [
        "print('Accuracy of LR model', accuracy_score(y_test, LR_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-06T15:49:54.957716Z",
          "iopub.status.busy": "2021-04-06T15:49:54.956070Z",
          "iopub.status.idle": "2021-04-06T15:49:54.981040Z",
          "shell.execute_reply": "2021-04-06T15:49:54.982060Z"
        },
        "papermill": {
          "duration": 0.519548,
          "end_time": "2021-04-06T15:49:54.982317",
          "exception": false,
          "start_time": "2021-04-06T15:49:54.462769",
          "status": "completed"
        },
        "tags": [],
        "id": "8YaE47vqSX5U"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, LR_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.451062,
          "end_time": "2021-04-06T15:49:55.924348",
          "exception": false,
          "start_time": "2021-04-06T15:49:55.473286",
          "status": "completed"
        },
        "tags": [],
        "id": "6DukqSv5SX5U"
      },
      "source": [
        "As we can see, we are obtaining a 0.99 acc by just training a Logistic Regression model. Sometimes the simplest solution is the best choice to solve a certain task if it can save us computation time. In any case, the results are very similar."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 8186.48888,
      "end_time": "2021-04-06T15:50:01.739837",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-04-06T13:33:35.250957",
      "version": "2.2.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12b572b8ad6b4b108b1ba62b178bd849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a57bcf265f08413cac0253c6fdbc1572",
              "IPY_MODEL_5529ff7d8e814e48822a88ef24ff81bc",
              "IPY_MODEL_75c21f3ae2a34a189ab835a3448e32bd"
            ],
            "layout": "IPY_MODEL_b7727b01edd845acbcff660a846ca5de"
          }
        },
        "a57bcf265f08413cac0253c6fdbc1572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604e7ff2cd7b450d85ed2073233066a5",
            "placeholder": "​",
            "style": "IPY_MODEL_7f5d918afe294340868ab0d4314c15aa",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "5529ff7d8e814e48822a88ef24ff81bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf111c7784db4d929e1812b31db44da9",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60654f522988419fad7f599441e81fac",
            "value": 231508
          }
        },
        "75c21f3ae2a34a189ab835a3448e32bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be90b602e3e74518b4eeeb0718ab6581",
            "placeholder": "​",
            "style": "IPY_MODEL_259783494f934557b28f05c5604f4a2a",
            "value": " 232k/232k [00:00&lt;00:00, 674kB/s]"
          }
        },
        "b7727b01edd845acbcff660a846ca5de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604e7ff2cd7b450d85ed2073233066a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5d918afe294340868ab0d4314c15aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf111c7784db4d929e1812b31db44da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60654f522988419fad7f599441e81fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be90b602e3e74518b4eeeb0718ab6581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259783494f934557b28f05c5604f4a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34c561f3606c4d59b5121427f6a054fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ba17b4a81274f2e825b29584396cc6c",
              "IPY_MODEL_1928a62cd09d43b09907676359490d45",
              "IPY_MODEL_de13aae110cc44a29727ec04663e6284"
            ],
            "layout": "IPY_MODEL_839020bfa94e4464b23c309bc2e3ef2b"
          }
        },
        "2ba17b4a81274f2e825b29584396cc6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20261a9ee7f34af492b4ed368406b91e",
            "placeholder": "​",
            "style": "IPY_MODEL_679870e0aa1c45a8af873bbed00f22ad",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "1928a62cd09d43b09907676359490d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2d32d3606546d08869939f214442ac",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a7d7f814f8844cbb8c84f87887b6f21",
            "value": 28
          }
        },
        "de13aae110cc44a29727ec04663e6284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c91f0a88f9e2410aa13d1e351c7f55a1",
            "placeholder": "​",
            "style": "IPY_MODEL_2a15d4a36e7e4bc49b147e0c5b7ee2e4",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.46kB/s]"
          }
        },
        "839020bfa94e4464b23c309bc2e3ef2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20261a9ee7f34af492b4ed368406b91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "679870e0aa1c45a8af873bbed00f22ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e2d32d3606546d08869939f214442ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7d7f814f8844cbb8c84f87887b6f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c91f0a88f9e2410aa13d1e351c7f55a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a15d4a36e7e4bc49b147e0c5b7ee2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7155b8b9bc54fc795a18a4b7ffe7214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce97b64f0e26471aa9c4e1c2ae570073",
              "IPY_MODEL_f9acbe188f5c44029159eafb25b53c5d",
              "IPY_MODEL_af05800354c84b39b245393e9ce59d16"
            ],
            "layout": "IPY_MODEL_963fff97ba4d4329b6fc9bb9e1a08171"
          }
        },
        "ce97b64f0e26471aa9c4e1c2ae570073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a2a3a5ce4d4a3b808216518fceecd8",
            "placeholder": "​",
            "style": "IPY_MODEL_24d9049644864e6fb01f6bdcc5b50a75",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "f9acbe188f5c44029159eafb25b53c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4219d943bd5b460197964c1753aa31f7",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87f4a594d0634a69bed099af82771d69",
            "value": 570
          }
        },
        "af05800354c84b39b245393e9ce59d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5bf61ced64a4718b8b4c2c14212ed99",
            "placeholder": "​",
            "style": "IPY_MODEL_889ec3936fce45418f7b2af6114c63a6",
            "value": " 570/570 [00:00&lt;00:00, 28.0kB/s]"
          }
        },
        "963fff97ba4d4329b6fc9bb9e1a08171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a2a3a5ce4d4a3b808216518fceecd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d9049644864e6fb01f6bdcc5b50a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4219d943bd5b460197964c1753aa31f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f4a594d0634a69bed099af82771d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5bf61ced64a4718b8b4c2c14212ed99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "889ec3936fce45418f7b2af6114c63a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6afe18b3778346068989ac8d21a60dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00a24a670838490da13f5786774bfe17",
              "IPY_MODEL_1948be8f3288454e9ecab1e3697c3512",
              "IPY_MODEL_3773e811e41e4bf8bc421cf676037e99"
            ],
            "layout": "IPY_MODEL_0da0bc303dde4d54b4b477dffe2da1c1"
          }
        },
        "00a24a670838490da13f5786774bfe17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3490bc3a904ccc98094d6fca478188",
            "placeholder": "​",
            "style": "IPY_MODEL_6727cd7665c949a9b2c81d7da457ea9f",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "1948be8f3288454e9ecab1e3697c3512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce0fde6917b4e8e8ddb75959f8f1bf3",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41dcc04cba5f47798f959983825ad2e9",
            "value": 440473133
          }
        },
        "3773e811e41e4bf8bc421cf676037e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_113149a4154549f492c22ae51d459a73",
            "placeholder": "​",
            "style": "IPY_MODEL_d20b91d8ada74f6aac01d8cb3b57f916",
            "value": " 440M/440M [00:01&lt;00:00, 399MB/s]"
          }
        },
        "0da0bc303dde4d54b4b477dffe2da1c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c3490bc3a904ccc98094d6fca478188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6727cd7665c949a9b2c81d7da457ea9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cce0fde6917b4e8e8ddb75959f8f1bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41dcc04cba5f47798f959983825ad2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "113149a4154549f492c22ae51d459a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20b91d8ada74f6aac01d8cb3b57f916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g8eJJ8ItSX5Q"
      ],
      "gpuClass": "premium"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}