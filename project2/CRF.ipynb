{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import packages, Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report, flat_f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_file(f):\n",
    "    data = open(f,'r').readlines()[1:]\n",
    "    row_id = [i.split('\\t')[0].strip() for i in data]\n",
    "    data = [i.split('\\t')[1].strip().split(' ') for i in data]\n",
    "    return row_id,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "row_id_text, texts = read_file('./review_data/REVIEW_TEXT.txt')\n",
    "row_id_tags, tags = read_file('./review_data/REVIEW_LABELSEQ.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model 1 (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def word2features(word, i, sent_len):\n",
    "    \n",
    "    features = {\n",
    "        'word.lower()': word.lower(),  # \n",
    "        'word.isdigit()': word.isdigit()\n",
    "    } \n",
    "        \n",
    "    return features\n",
    "\n",
    "def text2features(text):\n",
    "    return [word2features(txt, i, len(text)) for i, txt in enumerate(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Xb = [text2features(text) for text in texts]\n",
    "yb = tags\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(Xb, yb, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "F1 (macro): 0.519\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AE       0.73      0.41      0.52       807\n",
      "       B-SSI       0.78      0.55      0.65       149\n",
      "        I-AE       0.59      0.36      0.45      1485\n",
      "       I-SSI       0.10      0.04      0.06        79\n",
      "           O       0.89      0.96      0.92     12055\n",
      "\n",
      "    accuracy                           0.86     14575\n",
      "   macro avg       0.62      0.46      0.52     14575\n",
      "weighted avg       0.84      0.86      0.85     14575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/randy/.conda/envs/numpy_m1_build/lib/python3.10/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=['B-AE', 'B-SSI', 'I-AE', 'I-SSI', 'O'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "labels = ['B-AE','B-SSI','I-AE', 'I-SSI', 'O']\n",
    "crf = CRF()\n",
    "crf.fit(X_train, y_train) # train step \n",
    "y_pred = crf.predict(X_validation) # inference step\n",
    "report = flat_classification_report(y_validation, y_pred, labels=  labels)\n",
    "f1_score = flat_f1_score(y_validation, y_pred, average = 'macro', labels = labels)\n",
    "print(f\"Model 1\\nF1 (macro): {f1_score:.3f}\\nClassification report:\\n{report}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model 2 (added features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def word2features(word, i, sent_len):\n",
    "    # get POS\n",
    "    doc = nlp(word)\n",
    "    \n",
    "    features = {\n",
    "        'word.lower()': word.lower(),  # \n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word[0:3]': word[0:3],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-4:]': word[-4:],\n",
    "        'word.stemmed': re.sub(r'(.{2,}?)([aeiougyn]+$)',r'\\1', word.lower()),\n",
    "        'pos': [token.pos_ for token in doc][0],\n",
    "        \"is.stopword\": (word in stopwords.words())\n",
    "    } \n",
    "\n",
    "    if i == 0: \n",
    "        features['BOS'] = True\n",
    "    if i == sent_len-1:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "    return features\n",
    "\n",
    "def text2features(text):\n",
    "    return [word2features(txt, i, len(text)) for i, txt in enumerate(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = [text2features(text) for text in texts]\n",
    "y = tags\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n",
      "F1 (macro): 0.580\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AE       0.70      0.60      0.64       705\n",
      "       B-SSI       0.71      0.54      0.61       157\n",
      "        I-AE       0.58      0.55      0.57      1299\n",
      "       I-SSI       0.32      0.09      0.14       100\n",
      "           O       0.93      0.95      0.94     11926\n",
      "\n",
      "    accuracy                           0.89     14187\n",
      "   macro avg       0.65      0.55      0.58     14187\n",
      "weighted avg       0.88      0.89      0.88     14187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/randy/.conda/envs/numpy_m1_build/lib/python3.10/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=['B-AE', 'B-SSI', 'I-AE', 'I-SSI', 'O'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "labels = ['B-AE','B-SSI','I-AE', 'I-SSI', 'O']\n",
    "crf = CRF()\n",
    "crf.fit(X_train, y_train) # train step \n",
    "y_pred = crf.predict(X_validation) # inference step\n",
    "report = flat_classification_report(y_validation, y_pred, labels=  labels)\n",
    "f1_score = flat_f1_score(y_validation, y_pred, average = 'macro', labels = labels)\n",
    "print(f\"Model 2\\nF1 (macro): {f1_score:.3f}\\nClassification report:\\n{report}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model 3 (Hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# param_grid\n",
    "param_grid = {\n",
    "    'algorithm': ['lbfgs'],\n",
    "    'c1': [0, 0.5, 1],\n",
    "    'c2': [0, 0.5, 1],\n",
    "    'max_iterations': [50, 100, 200],\n",
    "    'delta': [1e-5, 1e-3, 0.01],\n",
    "    'epsilon': [1e-5, 1e-3, 0.01]\n",
    "}\n",
    "\n",
    "gcv = GridSearchCV(estimator = CRF(), param_grid = param_grid, n_jobs = -1, verbose = 3)\n",
    "\n",
    "gcv.fit(X_train, y_train) \n",
    "######### output deleted #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'lbfgs', 'c1': 0.5, 'c2': 0, 'delta': 1e-05, 'epsilon': 1e-05, 'max_iterations': 50}\n"
     ]
    }
   ],
   "source": [
    "print(gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3\n",
      "F1 (macro): 0.591\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        B-AE       0.70      0.61      0.65       705\n",
      "       B-SSI       0.73      0.54      0.62       157\n",
      "        I-AE       0.62      0.54      0.57      1299\n",
      "       I-SSI       0.33      0.11      0.17       100\n",
      "           O       0.93      0.96      0.94     11926\n",
      "\n",
      "    accuracy                           0.89     14187\n",
      "   macro avg       0.66      0.55      0.59     14187\n",
      "weighted avg       0.88      0.89      0.88     14187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/randy/.conda/envs/numpy_m1_build/lib/python3.10/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=['B-AE', 'B-SSI', 'I-AE', 'I-SSI', 'O'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "\n",
    "crf = CRF(algorithm = 'lbfgs', c1 = 0.5, c2 = 0, delta = 1e-5, epsilon = 1e-5, max_iterations = 50)\n",
    "crf.fit(X_train, y_train) # train step \n",
    "y_pred = crf.predict(X_validation) # inference step\n",
    "report = flat_classification_report(y_validation, y_pred, labels=  labels)\n",
    "f1_score = flat_f1_score(y_validation, y_pred, average = 'macro', labels = labels)\n",
    "print(f\"Model 3\\nF1 (macro): {f1_score:.3f}\\nClassification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/randy/.conda/envs/numpy_m1_build/lib/python3.10/site-packages/sklearn/__init__.py'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__file__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy_m1_build",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "5cd2dc2bc102a04a2cb17d6d5180f0d184562ab71498ad6d78c8ae3de727ddc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
